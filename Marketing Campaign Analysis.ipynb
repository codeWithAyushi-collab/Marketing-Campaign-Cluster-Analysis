# -*- coding: utf-8 -*-
"""
Created on Sat Feb 17 21:28:16 2024

@author: bhati
"""


import pandas as pd
import numpy as np
import seaborn as sns
import sklearn as sklearn
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler

pd.set_option("display.max_columns", None)
df=pd.read_csv("B:\DATASETS\marketing_campaign.csv",sep="\t")
print(df)
print(df.columns)
print(df.info())
print(df.describe)
print(df.nunique())

#dropping unique values
df = df.drop('ID', axis=1)
df = df.drop(['Z_CostContact', 'Z_Revenue'], axis=1)
df = df.drop('Dt_Customer', axis=1)
print(df.columns)

# Check for missing values
print(df.isnull().sum())
df['Income'].fillna(df['Income'].mean(), inplace=True)
print(df.columns)

#converting categorical values into numerical values
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
df['Education'] = label_encoder.fit_transform(df['Education'])
df['Marital_Status'] = label_encoder.fit_transform(df['Marital_Status'])
print(df)

# Standardize the dataset
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)
print(df)

# KMeans clustering
from sklearn.cluster import KMeans
k = 3
model = KMeans(n_clusters=k, init='k-means++', max_iter=500, n_init=10, random_state=42)
model.fit(df)
print(model.predict(df))
pred = model.fit_predict(df)

sns.scatterplot(x=df['Education'], y=df['Marital_Status'], hue=pred)
plt.xlabel('Education')
plt.ylabel('Marital_Status')
plt.title('K-Means Clustering')
plt.show()

# DBSCAN clustering
dbscan = DBSCAN(eps=0.5, min_samples=15)
dbscan.fit(df)
print(dbscan.fit(df))

labels = dbscan.labels_
core_samples = np.zeros_like(labels, dtype=bool)
core_samples[dbscan.core_sample_indices_] = True

sns.scatterplot(x=df['Education'], y=df['Marital_Status'],hue=labels)
plt.xlabel('Education') 
plt.ylabel('Marital_Status') 
plt.title('DBSCAN Clustering')
plt.show()

# Hierarchical clustering
hierarchical = AgglomerativeClustering(n_clusters=2)
hierarchical_labels = hierarchical.fit_predict(df)
print( hierarchical.fit_predict(df))

sns.scatterplot(x=df['Education'], y=df['Marital_Status'], hue=hierarchical_labels)
plt.xlabel('Education') 
plt.ylabel('Marital_Status') 
plt.show()

#dendrogram
from scipy.cluster.hierarchy import dendrogram, linkage
linkage_matrix=linkage(df,method='ward')
dendrogram(linkage_matrix)
plt.show()


"""
We did cluster analysis because it is used to group similar data points together 
based on characteristics. It is also useful for exploring patterns in datasets.

K-Means: suitable for well-separated spherical clusters.
DBSCAN: to handle irregular shapes and robust to outliers.
Hierarchical: for hierarchical tree structures in the data.

The combination of these techniques provides a understanding of the structures in the 
dataset, allowing for different shapes and densities of clusters to be identified. 
Clustering analysis approach is well-suited for exploring patterns in the 
Customer Personality Analysis dataset.

I groups clusters on basis of different education levels and marital status.

"""



